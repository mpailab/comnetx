{
  "cells": [
    {
      "metadata": {
        "id": "LEifDO_tXfX0"
      },
      "cell_type": "markdown",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6xBoiziW3hCI",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Notebook setup.\n",
        "%cd ..\n",
        "import random\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "from semantic_routing.benchmark import utils\n",
        "from semantic_routing.benchmark.graphs import city_graph\n",
        "from semantic_routing.benchmark.graphs import grid_graph\n",
        "from semantic_routing.benchmark.datasets import touring_dataset\n",
        "from semantic_routing.benchmark.query_engines import labeled_query_engines\n",
        "from semantic_routing.tokenization import tokenization\n",
        "\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=benchmark.DEFAULT_BERT_VOCAB\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV4ttcSQ70kj"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v0Zb10Si5lVm",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Setup dataset.\n",
        "poi_specs = utils.get_poi_specs(benchmark.POI_SPECS_PATH)\n",
        "engine = labeled_query_engines.HumanLabeledQueryEngine(poi_specs=poi_specs, splits=[0.95, 0, 0.05])\n",
        "rng = random.Random(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjwyhVcIPsBD"
      },
      "source": [
        "Let's generate a few datapoints and count the timing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sBzTY2q_UXx9",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Generate grid graph data.\n",
        "for _ in range(10):\n",
        "  datapoint = None\n",
        "  for _ in range(10):\n",
        "    seed = rng.randint(0, 1e8)\n",
        "    graph = grid_graph.GridGraph(poi_specs, 900, seed=seed, splits=[1, 0, 0])\n",
        "    data = touring_dataset.TouringDataset(tokenizer, graph, engine, poi_specs, 0, 128, 128)\n",
        "    try:\n",
        "      datapoint = data.sample_datapoint(True, 0, use_fresh=True)\n",
        "      break\n",
        "    except TimeoutError:\n",
        "      continue\n",
        "  print(datapoint[\"query_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W3pYj0mX5t0t",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Generate OSM data.\n",
        "for _ in range(5):\n",
        "  datapoint = None\n",
        "  for _ in range(10):\n",
        "    seed = rng.randint(0, 1e8)\n",
        "    graph = city_graph.CityGraph(poi_specs, 20000, seed=seed, splits=[1, 0, 0], use_test_city=True)\n",
        "    data = touring_dataset.TouringDataset(tokenizer, graph, engine, poi_specs, 0, 128, 128, max_segments=600, auto_simplify_datapoint=True)\n",
        "    try:\n",
        "      datapoint = data.sample_datapoint(True, 0, use_fresh=True)\n",
        "      break\n",
        "    except TimeoutError:\n",
        "      continue\n",
        "  print(datapoint[\"query_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kjGS6czgqOQy",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# For the networkx graph (may be contracted)\n",
        "datapoint[\"parent\"].road_graph.nx_graph\n",
        "# Uncontracted networkx graph\n",
        "data.road_graph.nx_graph\n",
        "# Rest of the task information:\n",
        "print(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTFZFB2PSIEc"
      },
      "source": [
        "Datapoint features can be padded to a consistent length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZGlWEKO_PiEG",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Datapoint feature shapes.\n",
        "from absl import app\n",
        "import sys\n",
        "app.parse_flags_with_usage([\"\"])\n",
        "\n",
        "datapoint = None\n",
        "for _ in range(10):\n",
        "  seed = rng.randint(0, 1e8)\n",
        "  graph = city_graph.CityGraph(poi_specs, 20000, seed=seed, splits=[1, 0, 0], use_test_city=True)\n",
        "  data = touring_dataset.TouringDataset(tokenizer, graph, engine, poi_specs, 0, 128, 128, max_segments=600, auto_simplify_datapoint=True)\n",
        "  try:\n",
        "    datapoint = data.sample_datapoint(False, 0, use_fresh=True)\n",
        "    break\n",
        "  except TimeoutError:\n",
        "    continue\n",
        "\n",
        "print(\"Shape of datapoint features with padding.\")\n",
        "for k, v in datapoint[\"parent\"].featurize_datapoint(datapoint, pad=True).items():\n",
        "  if isinstance(v, int):\n",
        "    print(k, \"TensorShape(Scalar)\")\n",
        "    continue\n",
        "  pprint.pprint((k, v.shape))\n",
        "print()\n",
        "print(\"Shape of datapoint features without padding.\")\n",
        "for k, v in datapoint[\"parent\"].featurize_datapoint(datapoint, pad=False).items():\n",
        "  if isinstance(v, int):\n",
        "    print(k, \"TensorShape(Scalar)\")\n",
        "    continue\n",
        "  pprint.pprint((k, v.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4cuGsZSMqq"
      },
      "source": [
        "We can evaluate routes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0Q3Y37y5Gf_r",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Datapoint evaluation statistics.\n",
        "\n",
        "data = datapoint[\"parent\"]\n",
        "\n",
        "print(\"Statistics of ground-truth route with TERM\")\n",
        "x, p = data.road_graph.get_shortest_path_len(datapoint[\"edgelist\"][0], datapoint[\"end\"], datapoint[\"query_data\"], return_path=True)\n",
        "datapoint[\"edgelist\"] = p + (data.term_token,)\n",
        "datapoint[\"ground_truth\"] = None\n",
        "datapoint[\"candidates\"] = ()\n",
        "pprint.pprint(data.evaluate_datapoint(datapoint))\n",
        "print()\n",
        "print(\"Statistics of ground-truth route without TERM\")\n",
        "x, p = data.road_graph.get_shortest_path_len(datapoint[\"edgelist\"][0], datapoint[\"end\"], datapoint[\"query_data\"], return_path=True)\n",
        "datapoint[\"edgelist\"] = p\n",
        "datapoint[\"ground_truth\"] = None\n",
        "datapoint[\"candidates\"] = ()\n",
        "pprint.pprint(data.evaluate_datapoint(datapoint))\n",
        "print()\n",
        "print(\"Statistics of ground-truth route without last edge\")\n",
        "x, p = data.road_graph.get_shortest_path_len(datapoint[\"edgelist\"][0], datapoint[\"end\"], datapoint[\"query_data\"], return_path=True)\n",
        "datapoint[\"edgelist\"] = p[:-1]\n",
        "datapoint[\"ground_truth\"] = None\n",
        "datapoint[\"candidates\"] = ()\n",
        "pprint.pprint(data.evaluate_datapoint(datapoint))\n",
        "print()\n",
        "print(\"Statistics of ground-truth route ignoring POI\")\n",
        "x, p = data.road_graph.get_shortest_path_len(datapoint[\"edgelist\"][0], datapoint[\"end\"], {\"linear\": \"\", \"pois\": ()}, return_path=True)\n",
        "datapoint[\"edgelist\"] = p\n",
        "datapoint[\"ground_truth\"] = None\n",
        "datapoint[\"candidates\"] = ()\n",
        "pprint.pprint(data.evaluate_datapoint(datapoint))\n",
        "print()\n",
        "print(\"Statistics of ground-truth route ignoring POI and without last edge\")\n",
        "x, p = data.road_graph.get_shortest_path_len(datapoint[\"edgelist\"][0], datapoint[\"end\"], {\"linear\": \"\", \"pois\": ()}, return_path=True)\n",
        "datapoint[\"edgelist\"] = p[:-1]\n",
        "datapoint[\"ground_truth\"] = None\n",
        "datapoint[\"candidates\"] = ()\n",
        "pprint.pprint(data.evaluate_datapoint(datapoint))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
