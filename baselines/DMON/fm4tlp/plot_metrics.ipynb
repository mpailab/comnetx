{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY7vcrsHXgPv"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmt-QvUjmLQ2",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "import itertools\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.compat.v1 as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOi7qTdjMJ_L"
      },
      "outputs": [],
      "source": [
        "if 'gfile' not in sys.modules:\n",
        "  gfile = tf.io.gfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL4RQkUzlY-u"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = '/your/project/folder/here'\n",
        "SUBDIR = 'your_subdir'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8WR9dqctjKW"
      },
      "outputs": [],
      "source": [
        "MODELS = ['tgn', 'edgebank', 'tgn_structmap']\n",
        "DATA = ['tgbl_flight;AS;AS;AF']\n",
        "EXPERIMENTS = [\n",
        "    'transductive',\n",
        "    'transfer_no_warmstart',\n",
        "    'transfer_warmstart',\n",
        "]\n",
        "MODELS_EXPERIMENTS = [\n",
        "    'tgn-transfer_no_warmstart',\n",
        "    'tgn-transfer_warmstart',\n",
        "    'tgn_structmap-transfer_no_warmstart',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOcfnLo51XCU"
      },
      "outputs": [],
      "source": [
        "# Transform inputs.\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class DatasetSpec:\n",
        "  dataset: str = dataclasses.field(default_factory=str)\n",
        "  train_split: str = dataclasses.field(default_factory=str)\n",
        "  val_split: str = dataclasses.field(default_factory=str)\n",
        "  test_split: str = dataclasses.field(default_factory=str)\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class ExperimentResults:\n",
        "  experiment: str = dataclasses.field(default_factory=str)\n",
        "  train_results: dict[str, float] = dataclasses.field(default_factory=dict)\n",
        "  test_results: dict[str, float] = dataclasses.field(default_factory=dict)\n",
        "  val_warmstart_loss_metrics: pd.DataFrame = dataclasses.field(\n",
        "      default_factory=pd.DataFrame\n",
        "  )\n",
        "  val_loss_metrics: pd.DataFrame = dataclasses.field(\n",
        "      default_factory=pd.DataFrame\n",
        "  )\n",
        "  test_warmstart_loss_metrics: pd.DataFrame = dataclasses.field(\n",
        "      default_factory=pd.DataFrame\n",
        "  )\n",
        "  test_loss_metrics: pd.DataFrame = dataclasses.field(\n",
        "      default_factory=pd.DataFrame\n",
        "  )\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class ModelResults:\n",
        "  model: str = dataclasses.field(default_factory=str)\n",
        "  experiment_results: dict[str, ExperimentResults] = dataclasses.field(\n",
        "      default_factory=dict\n",
        "  )\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class DatasetResults:\n",
        "  dataset: str = dataclasses.field(default_factory=str)\n",
        "  model_results: dict[str, ModelResults] = dataclasses.field(\n",
        "      default_factory=dict\n",
        "  )\n",
        "\n",
        "\n",
        "DATASET_SPECS = []\n",
        "DATASETS = []\n",
        "for dataset_string in DATA:\n",
        "  dataset, train_split, val_split, test_split = dataset_string.split(';')\n",
        "  DATASETS.append(dataset)\n",
        "  DATASET_SPECS.append(DatasetSpec(dataset, train_split, val_split, test_split))\n",
        "\n",
        "RESULTS_SUBDIR = os.path.join(PROJECT_ROOT, 'experiments', SUBDIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jnhONMomItq",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ALL_RESULTS = {}\n",
        "train_results_df = pd.DataFrame(\n",
        "    index=pd.MultiIndex.from_product(\n",
        "        [MODELS, EXPERIMENTS], names=['Model', 'Experiment']\n",
        "    ),\n",
        "    columns=pd.MultiIndex.from_product(\n",
        "        [DATASETS, ['auc', 'mrr']], names=['Dataset', 'Metric']\n",
        "    ),\n",
        ")\n",
        "test_results_df = pd.DataFrame(\n",
        "    index=pd.MultiIndex.from_product(\n",
        "        [MODELS, EXPERIMENTS], names=['Model', 'Experiment']\n",
        "    ),\n",
        "    columns=pd.MultiIndex.from_product(\n",
        "        [DATASETS, ['auc', 'mrr']], names=['Dataset', 'Metric']\n",
        "    ),\n",
        ")\n",
        "for dataset_spec in DATASET_SPECS:\n",
        "  dataset_results = DatasetResults(dataset=dataset_spec.dataset)\n",
        "  for model in MODELS:\n",
        "    model_results = ModelResults(model=model)\n",
        "    model_dataset_folder = os.path.join(\n",
        "        RESULTS_SUBDIR,\n",
        "        dataset_spec.dataset,\n",
        "        'results',\n",
        "        f'{model}_{dataset_spec.dataset}_{dataset_spec.train_split}_{dataset_spec.val_split}',\n",
        "    )\n",
        "    for experiment in EXPERIMENTS:\n",
        "      if str(model) + '-' + str(experiment) in MODELS_EXPERIMENTS:\n",
        "        # Extract results for train.\n",
        "        experiment_results = ExperimentResults(experiment=experiment)\n",
        "        with gfile.GFile(\n",
        "            os.path.join(\n",
        "                model_dataset_folder, f'{experiment}_results_train.json'\n",
        "            ),\n",
        "            'r',\n",
        "        ) as f:\n",
        "          experiment_results.train_results = json.load(f)\n",
        "        with gfile.GFile(\n",
        "            os.path.join(model_dataset_folder, f'{experiment}_val_loss.csv'),\n",
        "            'r',\n",
        "        ) as f:\n",
        "          experiment_results.val_loss_metrics = pd.read_csv(f)\n",
        "        if not 'no_warmstart' in experiment:\n",
        "          with gfile.GFile(\n",
        "              os.path.join(model_dataset_folder, f'{experiment}_val_loss.csv'),\n",
        "              'r',\n",
        "          ) as f:\n",
        "            experiment_results.val_warmstart_loss_metrics = pd.read_csv(f)\n",
        "        train_results_df.loc[model, experiment].at[\n",
        "            dataset_spec.dataset, 'auc'\n",
        "        ] = experiment_results.train_results['auc']\n",
        "        train_results_df.loc[model, experiment].at[\n",
        "            dataset_spec.dataset, 'mrr'\n",
        "        ] = experiment_results.train_results['val mrr']\n",
        "\n",
        "        # Extract results for test.\n",
        "        with tf.io.gfile.GFile(\n",
        "            os.path.join(\n",
        "                model_dataset_folder,\n",
        "                f'{experiment}_results_test_{dataset_spec.test_split}.json',\n",
        "            ),\n",
        "            'r',\n",
        "        ) as f:\n",
        "          experiment_results.test_results = json.load(f)\n",
        "        with tf.io.gfile.GFile(\n",
        "            os.path.join(\n",
        "                model_dataset_folder,\n",
        "                f'{experiment}_test_{dataset_spec.test_split}_loss.csv',\n",
        "            ),\n",
        "            'r',\n",
        "        ) as f:\n",
        "          experiment_results.test_loss_metrics = pd.read_csv(f)\n",
        "        if not 'no_warmstart' in experiment:\n",
        "          with tf.io.gfile.GFile(\n",
        "              os.path.join(\n",
        "                  model_dataset_folder,\n",
        "                  f'{experiment}_test_{dataset_spec.test_split}_loss.csv',\n",
        "              ),\n",
        "              'r',\n",
        "          ) as f:\n",
        "            experiment_results.test_warmstart_loss_metrics = pd.read_csv(f)\n",
        "\n",
        "        test_results_df.loc[model, experiment].at[\n",
        "            dataset_spec.dataset, 'auc'\n",
        "        ] = experiment_results.test_results['test auc']\n",
        "        test_results_df.loc[model, experiment].at[\n",
        "            dataset_spec.dataset, 'mrr'\n",
        "        ] = experiment_results.test_results['test mrr']\n",
        "\n",
        "        model_results.experiment_results[experiment] = experiment_results\n",
        "\n",
        "    dataset_results.model_results[model] = model_results\n",
        "  ALL_RESULTS[dataset_spec.dataset] = dataset_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbu84WAOOLZ0",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_eval_metric_curves(\n",
        "    dataset='tgbl_wiki',\n",
        "    experiments=EXPERIMENTS,\n",
        "    models=['tgn', 'tgn_structmap'],\n",
        "    model_experiemnts=MODELS_EXPERIMENTS,\n",
        "    val=True,\n",
        "    metric_name='perf',\n",
        "    batches_plot=100,\n",
        "    plot_warmstart_period=False,\n",
        "    master_results_dict=ALL_RESULTS,\n",
        "    dataset_spec=DATASET_SPECS,\n",
        "):\n",
        "\n",
        "  eval_df_string = 'val' if val else 'test'\n",
        "  plot_dataframes = []\n",
        "\n",
        "  # Make sure that if there is warmstart experiment that it comes first.\n",
        "  experiment_list = copy.deepcopy(experiments)\n",
        "  first_experiment = ''\n",
        "  for experiment in experiment_list:\n",
        "    if 'no_warmstart' not in experiment:\n",
        "      first_experiment = copy.deepcopy(experiment)\n",
        "  experiment_list.remove(first_experiment)\n",
        "  experiment_list = [first_experiment] + experiment_list\n",
        "\n",
        "  warmstart_end_index = 0\n",
        "  for idx, experiment in enumerate(experiment_list):\n",
        "    for model in models:\n",
        "      if str(model) + '-' + str(experiment) in model_experiemnts:\n",
        "        if ('no_warmstart' not in experiment) and plot_warmstart_period:\n",
        "          warmstart_df = getattr(\n",
        "              master_results_dict[dataset]\n",
        "              .model_results[model]\n",
        "              .experiment_results[experiment],\n",
        "              f'{eval_df_string}_warmstart_loss_metrics',\n",
        "          )\n",
        "          if idx == 0:\n",
        "            warmstart_end_index = len(warmstart_df)\n",
        "          warmstart_df['batch_index'] = list(range(warmstart_end_index))\n",
        "          warmstart_df = warmstart_df.melt(\n",
        "              id_vars=['batch_index'],\n",
        "              value_vars=['loss', 'perf', 'auc'],\n",
        "              value_name='metric_value',\n",
        "              var_name='metric_name',\n",
        "          )\n",
        "          warmstart_df['experiment'] = model + '-' + experiment\n",
        "          warmstart_df = warmstart_df[warmstart_df.metric_name == metric_name]\n",
        "          warmstart_df['period'] = 'warmstart'\n",
        "          plot_dataframes.append(warmstart_df.head(batches_plot))\n",
        "\n",
        "        eval_df = getattr(\n",
        "            master_results_dict[dataset]\n",
        "            .model_results[model]\n",
        "            .experiment_results[experiment],\n",
        "            f'{eval_df_string}_loss_metrics',\n",
        "        )\n",
        "        eval_df['batch_index'] = list(\n",
        "            range(warmstart_end_index, len(eval_df) + warmstart_end_index)\n",
        "        )\n",
        "        eval_df = eval_df.melt(\n",
        "            id_vars=['batch_index'],\n",
        "            value_vars=['loss', 'perf', 'auc'],\n",
        "            value_name='metric_value',\n",
        "            var_name='metric_name',\n",
        "        )\n",
        "        eval_df['experiment'] = model + '-' + experiment\n",
        "        eval_df = eval_df[eval_df.metric_name == metric_name]\n",
        "        eval_df['period'] = 'eval'\n",
        "        plot_dataframes.append(eval_df.head(batches_plot))\n",
        "\n",
        "  # Make plot.\n",
        "  master_plot_dataframe = pd.concat(plot_dataframes, axis=0)\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  plt.title(f'{dataset} {eval_df_string} {metric_name}')\n",
        "  sns.lineplot(\n",
        "      data=master_plot_dataframe,\n",
        "      x='batch_index',\n",
        "      y='metric_value',\n",
        "      hue='experiment',\n",
        "      style='period',\n",
        "  )\n",
        "  plt.show()\n",
        "  return master_plot_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9uzcymifl8v",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(\n",
        "    dataset='tgbl_flight', metric_name='loss', batches_plot=60, val=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoM0Jsf0j94h",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(\n",
        "    dataset='tgbl_flight', metric_name='perf', batches_plot=100, val=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZHdRykIkEAq",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(\n",
        "    dataset='tgbl_flight', metric_name='auc', batches_plot=100, val=False\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1LSHHrBHWDs-o_y68I_Lxv5fISoe15WFS",
          "timestamp": 1724442130455
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
